<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="CrossA11y Project Page">
  <meta property="og:title" content="CrossA11y"/>
  <meta property="og:description" content="CrossA11y: Identifying Video Accessibility Issues via Cross-modal Grounding"/>
  <meta property="og:url" content="https://liubruce.me/CrossA11y"/>

  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="audio description, closed caption, video, accessibility, CHI, UIST">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>CrossA11y</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CrossA11y: Identifying Video Accessibility Issues via Cross-modal Grounding</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://liubruce.me/" target="_blank">Xingyu Bruce Liu</a><sup>1</sup>,
              </span>
              
              <span class="author-block">
                <a href="https://www.violynnewang.com/" target="_blank">Ruolin Wang</a><sup>1</sup>,
              </span>
                
                
              <span class="author-block">
                <a href="https://dingzeyu.li/" target="_blank">Dingzeyu Li</a><sup>2</sup>,
              </span>

              <span class="author-block">
                <a href="https://hci.prof/" target="_blank">Xiang 'Anthony' Chen</a><sup>1</sup>,
              </span>

              <span class="author-block">
                <a href="https://amypavel.com/" target="_blank">Amy Pavel</a><sup>3</sup>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">UCLA<sup>1</sup>, Adobe Research<sup>2</sup>, UT Austin<sup>3</sup></span>
                      <br>ACM UIST 2022 (Best Paper Award üèÜ)</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://dl.acm.org/doi/10.1145/3526113.3545703" target="_blank" class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/xybruceliu/CrossA11y-demo" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- YouTube Video -->
                <span class="link-block">
                  <a href="https://youtu.be/HDqjnHOZ7J8" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>

                <!-- Talk Recording -->
                <span class="link-block">
                  <a href="https://youtu.be/2tvE5n_5SKo?list=LL&t=2011" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-microphone"></i>
                    </span>
                    <span>Talk</span>
                  </a>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2208.11144" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser figure-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png" alt="Teaser figure of CrossA11y"/>
      <h2 class="subtitle has-text-justified">
        Our system (A) identifes accessibility issues by locating modality asymmetries (in red) between audio segments and video segments using cross-modal grounding. (B) lets authors address accessibility issues using the CrossA11y interface to write captions and video descriptions, and (C) creates a more accessible video from the authored descriptions.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Authors make their videos visually accessible by adding audio descriptions (AD), and auditorily accessible by adding closed captions (CC). However, creating AD and CC is challenging and tedious, especially for non-professional describers and captioners, due to the difficulty of identifying accessibility problems in videos. A video author will have to watch the video through and manually check for inaccessible information frame-by-frame, for both visual and auditory modalities. In this paper, we present CrossA11y, a system that helps authors efficiently detect and address visual and auditory accessibility issues in videos. Using cross-modal grounding analysis, CrossA11y automatically measures accessibility of visual and audio segments in a video by checking for modality asymmetries. CrossA11y then displays these segments and surfaces visual and audio accessibility issues in a unified interface, making it intuitive to locate, review, script AD/CC in-place, and preview the described and captioned video immediately. We demonstrate the effectiveness of CrossA11y through a lab study with 11 participants, comparing to existing baseline.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->





<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/HDqjnHOZ7J8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{10.1145/3526113.3545703,
  author = {Liu, Xingyu Bruce and Wang, Ruolin and Li, Dingzeyu and Chen, Xiang Anthony and Pavel, Amy},
  title = {CrossA11y: Identifying Video Accessibility Issues via Cross-modal Grounding},
  year = {2022},
  isbn = {9781450393201},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3526113.3545703},
  doi = {10.1145/3526113.3545703},
  booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {43},
  numpages = {14},
  keywords = {accessibility, audio description, closed caption, video},
  location = {Bend, OR, USA},
  series = {UIST '22}
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            ¬© Copyright Xingyu Bruce Liu. Built with the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
